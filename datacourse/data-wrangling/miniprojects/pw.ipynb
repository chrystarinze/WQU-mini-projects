{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from static_grader import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PW Miniproject\n",
    "## Introduction\n",
    "\n",
    "The objective of this miniproject is to exercise your ability to use basic Python data structures, define functions, and control program flow. We will be using these concepts to perform some fundamental data wrangling tasks such as joining data sets together, splitting data into groups, and aggregating data into summary statistics.\n",
    "**Please do not use `pandas` or `numpy` to answer these questions.**\n",
    "\n",
    "We will be working with medical data from the British NHS on prescription drugs. Since this is real data, it contains many ambiguities that we will need to confront in our analysis. This is commonplace in data science, and is one of the lessons you will learn in this miniproject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "We first need to download the data we'll be using from Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pw-data\n",
    "wget http://dataincubator-wqu.s3.amazonaws.com/pwdata/201701scripts_sample.json.gz -nc -P ./pw-data\n",
    "wget http://dataincubator-wqu.s3.amazonaws.com/pwdata/practices.json.gz -nc -P ./pw-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The first step of the project is to read in the data. We will discuss reading and writing various kinds of files later in the course, but the code below should get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "#import simplejson as json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./pw-data/201701scripts_sample.json.gz', 'rb') as f:\n",
    "    scripts = json.load(f)\n",
    "\n",
    "with gzip.open('./pw-data/practices.json.gz', 'rb') as f:\n",
    "    practices = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set comes from Britain's National Health Service. The `scripts` variable is a list of prescriptions issued by NHS doctors. Each prescription is represented by a dictionary with various data fields: `'practice'`, `'bnf_code'`, `'bnf_name'`, `'quantity'`, `'items'`, `'nic'`, and `'act_cost'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [glossary of terms](http://webarchive.nationalarchives.gov.uk/20180328130852tf_/http://content.digital.nhs.uk/media/10686/Download-glossary-of-terms-for-GP-prescribing---presentation-level/pdf/PLP_Presentation_Level_Glossary_April_2015.pdf/) and [FAQ](http://webarchive.nationalarchives.gov.uk/20180328130852tf_/http://content.digital.nhs.uk/media/10048/FAQs-Practice-Level-Prescribingpdf/pdf/PLP_FAQs_April_2015.pdf/) is available from the NHS regarding the data. Below we supply a data dictionary briefly describing what these fields mean.\n",
    "\n",
    "| Data field |Description|\n",
    "|:----------:|-----------|\n",
    "|`'practice'`|Code designating the medical practice issuing the prescription|\n",
    "|`'bnf_code'`|British National Formulary drug code|\n",
    "|`'bnf_name'`|British National Formulary drug name|\n",
    "|`'quantity'`|Number of capsules/quantity of liquid/grams of powder prescribed|\n",
    "| `'items'`  |Number of refills (e.g. if `'quantity'` is 30 capsules, 3 `'items'` means 3 bottles of 30 capsules)|\n",
    "|  `'nic'`   |Net ingredient cost|\n",
    "|`'act_cost'`|Total cost including containers, fees, and discounts|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `practices` variable is a list of member medical practices of the NHS. Each practice is represented by a dictionary containing identifying information for the medical practice. Most of the data fields are self-explanatory. Notice the values in the `'code'` field of `practices` match the values in the `'practice'` field of `scripts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practices[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following questions we will ask you to explore this data set. You may need to combine pieces of the data set together in order to answer some questions. Not every element of the data set will be used in answering the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: summary_statistics\n",
    "\n",
    "Our beneficiary data (`scripts`) contains quantitative data on the number of items dispensed (`'items'`), the total quantity of item dispensed (`'quantity'`), the net cost of the ingredients (`'nic'`), and the actual cost to the patient (`'act_cost'`). Whenever working with a new data set, it can be useful to calculate summary statistics to develop a feeling for the volume and character of the data. This makes it easier to spot trends and significant features during further stages of analysis.\n",
    "\n",
    "Calculate the sum, mean, standard deviation, and quartile statistics for each of these quantities. Format your results for each quantity as a list: `[sum, mean, standard deviation, 1st quartile, median, 3rd quartile]`. We'll create a `tuple` with these lists for each quantity as a final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(qty):\n",
    "    cont = []\n",
    "    for dict in scripts:\n",
    "        cont.append(dict[qty])\n",
    "        \n",
    "    return cont\n",
    "    \n",
    "print(len(get('items')))\n",
    "get('items')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def describe(key):\n",
    "n = len(scripts)\n",
    "total = sum([script[key] for script in scripts])\n",
    "avg = total / n\n",
    "s = (sum([(script[key] - avg)**2 for script in scripts])/n)**(1/2)\n",
    "\n",
    "sorted_values = sorted(scripts, key = lambda i: i[key])\n",
    "\n",
    "q25 = sorted_values[int((1/4)*(n+1)-1)][key]\n",
    "med = sorted_values[int((2/4)*(n+1)-1)][key]\n",
    "q75 = sorted_values[int((3/4)*(n+1)-1)][key]\n",
    "\n",
    "return (total, avg, s, q25, med, q75)'''\n",
    "\n",
    "\n",
    "\n",
    "keys = scripts\n",
    "def describe(key):\n",
    "    \n",
    "    n = len(scripts)\n",
    "    total = sum(get(key))\n",
    "    avg = sum(get(key))/len(get(key))\n",
    "    s = (sum([(ky - avg)**2 for ky in get(key)])/(len(get(key)) - 1))**0.5\n",
    "    \n",
    "    \n",
    "    sorted_values = sorted(scripts, key = lambda i: i[key])\n",
    "\n",
    "    q25 = sorted_values[int((1/4)*(n+1)-1)][key]\n",
    "    med = sorted_values[int((2/4)*(n+1)-1)][key]\n",
    "    q75 = sorted_values[int((3/4)*(n+1)-1)][key]\n",
    "\n",
    "    return (total, avg, s, q25, med, q75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = [('items', describe('items')),\n",
    "           ('quantity', describe('quantity')),\n",
    "           ('nic', describe('nic')),\n",
    "           ('act_cost', describe('act_cost'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.score.pw__summary_statistics(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: most_common_item\n",
    "\n",
    "Often we are not interested only in how the data is distributed in our entire data set, but within particular groups -- for example, how many items of each drug (i.e. `'bnf_name'`) were prescribed? Calculate the total items prescribed for each `'bnf_name'`. What is the most commonly prescribed `'bnf_name'` in our data?\n",
    "\n",
    "To calculate this, we first need to split our data set into groups corresponding with the different values of `'bnf_name'`. Then we can sum the number of items dispensed within in each group. Finally we can find the largest sum.\n",
    "\n",
    "We'll use `'bnf_name'` to construct our groups. You should have *5619* unique values for `'bnf_name'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to construct \"groups\" identified by `'bnf_name'`, where each group is a collection of prescriptions (i.e. dictionaries from `scripts`). We'll construct a dictionary called `groups`, using `bnf_names` as the keys. We'll represent a group with a `list`, since we can easily append new members to the group. To split our `scripts` into groups by `'bnf_name'`, we should iterate over `scripts`, appending prescription dictionaries to each group as we encounter them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_names = {d['bnf_name'] for d in scripts}\n",
    "groups = {name: [] for name in bnf_names}\n",
    "# Now loop through scripts and append the elements to the right key in groups dict\n",
    "for script in scripts:\n",
    "    groups[script['bnf_name']].append(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_item =[max([(sum([member['items'] for member in group]),name) for name, group in groups.items()])[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_into_dictn (qty1, qty2):\n",
    "    groupz = {Name: [] for Name in bnf_names}\n",
    "    for script in scripts:\n",
    "        if script[qty1] in groupz:\n",
    "            groupz[script[qty1]].append(script[qty2])\n",
    "    \n",
    "    return groupz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = group_into_dictn('bnf_name', 'items')\n",
    "print(groups)\n",
    "\n",
    "#groups = {name: [] for name in bnf_names}\n",
    "#for script in scripts:\n",
    "    # INSERT ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sum = []\n",
    "for i in groups.values():\n",
    "    group_sum.append(sum(i))\n",
    "    \n",
    "print(group_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Note that max sum = %d' %max(group_sum))\n",
    "summed_group = dict(zip(bnf_names, group_sum))\n",
    "print('Total qty of drugs sold i.e sum(group_sum) = %d' %sum(group_sum))\n",
    "print('Confirmation of total qty of drugs sold i.e sum(get(\\'items\\')) = %d' %sum(get('items')))\n",
    "print('length of sumed_group = %d' %len(summed_group))\n",
    "summed_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've constructed our groups we should sum up `'items'` in each group and find the `'bnf_name'` with the largest sum. The result, `max_item`, should have the form `[(bnf_name, item total)]`, e.g. `[('Foobar', 2000)]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in summed_group:\n",
    "    if summed_group[key] == max(group_sum):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_item = [(\"Omeprazole_Cap E/C 20mg\", 113826)]\n",
    "#max_item = [(\"\", 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIP:** If you are getting an error from the grader below, please make sure your answer conforms to the correct format of `[(bnf_name, item total)]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  1.0\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "grader.score.pw__most_common_item(max_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** Write a function that constructs groups as we did above. The function should accept a list of dictionaries (e.g. `scripts` or `practices`) and a tuple of fields to `groupby` (e.g. `('bnf_name')` or `('bnf_name', 'post_code')`) and returns a dictionary of groups. The following questions will require you to aggregate data in groups, so this could be a useful function for the rest of the miniproject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_field(data, fields):\n",
    "    names = {tuple(item[field] for field in fields) for item in data}\n",
    "    groups = {name: [] for name in names}\n",
    "    for item in data:\n",
    "        name = tuple(item[field] for field in fields)\n",
    "        groups[name].append(item)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def group_by_field(data, field1, field2 ):\n",
    "    groups = {Name: [] for Name in bnf_names}\n",
    "    for script in data:\n",
    "        if script[field1] in groups:\n",
    "            groups[script[field1]].append(script[field2])\n",
    "    \n",
    "    return groups'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a405a84abfe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_max_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtest_max_item\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "groups = group_by_field(scripts, ('bnf_name', 'items'))\n",
    "test_max_item = \n",
    "\n",
    "assert test_max_item == max_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: postal_totals\n",
    "\n",
    "Our data set is broken up among different files. This is typical for tabular data to reduce redundancy. Each table typically contains data about a particular type of event, processes, or physical object. Data on prescriptions and medical practices are in separate files in our case. If we want to find the total items prescribed in each postal code, we will have to _join_ our prescription data (`scripts`) to our clinic data (`practices`).\n",
    "\n",
    "Find the total items prescribed in each postal code, representing the results as a list of tuples `(post code, total items prescribed)`. Sort your results ascending alphabetically by post code and take only results from the first 100 post codes. Only include post codes if there is at least one prescription from a practice in that post code.\n",
    "\n",
    "**NOTE:** Some practices have multiple postal codes associated with them. Use the alphabetically first postal code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join `scripts` and `practices` based on the fact that `'practice'` in `scripts` matches `'code'` in `practices`. However, we must first deal with the repeated values of `'code'` in `practices`. We want the alphabetically first postal codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format given by instructor\n",
    "'''practice_postal = {}\n",
    "for practice in practices:\n",
    "    if practice['code'] in practice_postal:\n",
    "        practice_postal[practice['code']] = ...\n",
    "    else:\n",
    "        practice_postal[practice['code']] = ...\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My previous attempt. Was corect but didn't support exercise 4\n",
    "'''def nget(qty):\n",
    "    content = []\n",
    "    for dict in practices:\n",
    "        content.append(dict[qty])\n",
    "        \n",
    "    return content\n",
    "\n",
    "def group_by_fieldd(data, field1, field2 ):\n",
    "    unq_field1 = list(set(nget(field1)))\n",
    "    ngroups = {Name: [] for Name in unq_field1}\n",
    "    for script in data:\n",
    "        if script[field1] in ngroups:\n",
    "            ngroups[script[field1]].append(script[field2])\n",
    "    \n",
    "    return ngroups\n",
    "\n",
    "\n",
    "\n",
    "practice_postal = group_by_fieldd(practices, 'code', 'post_code')\n",
    "practice_postal\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thi approach also worked fine\n",
    "'''\n",
    "practice_postal_sorted = []\n",
    "for i in practice_postal.values():\n",
    "    i.sort()\n",
    "    practice_postal_sorted.append(i)\n",
    "    \n",
    "print(practice_postal_sorted)\n",
    "\n",
    "practice_postal_sorted_01 = []\n",
    "for lizt in practice_postal_sorted:\n",
    "    practice_postal_sorted_01.append(lizt[0])\n",
    "\n",
    "practice_postal_sorted_01\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part of my working attempt. But this cell takes time to run\n",
    "'''\n",
    "for value in practice_postal_sorted_01:\n",
    "    i = 0\n",
    "    for key in practice_postal:\n",
    "        practice_postal[key] = practice_postal_sorted_01[i]\n",
    "        i += 1\n",
    "\n",
    "practice_postal\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_field(data, fields):\n",
    "    names = {tuple(item[field] for field in fields) for item in data}\n",
    "    groups = {name: [] for name in names}\n",
    "    for item in data:\n",
    "        name = tuple(item[field] for field in fields)\n",
    "        groups[name].append(item)\n",
    "    return groups\n",
    "\n",
    "practice_postal = {}\n",
    "for practice in practices:\n",
    "    code = practice['code']\n",
    "    if code not in practice_postal:\n",
    "        practice_postal[code] = practice['post_code']\n",
    "    else:\n",
    "        practice_postal[code] = min(practice_postal[code], practice['post_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SK11 6JL'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_postal['N81013']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge:** This is an aggregation of the practice data grouped by practice codes. Write an alternative implementation of the above cell using the `group_by_field` function you defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert practice_postal['K82019'] == 'HP21 8TR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can join `practice_postal` to `scripts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = scripts[:]\n",
    "\n",
    "for script in joined:\n",
    "    script['post_code'] = practice_postal[script['practice']]\n",
    "\n",
    "pc_grouped = list(group_by_field(joined, ('post_code',)).items())\n",
    "\n",
    "items_by_post = [(pc[0], sum(group['items'] for group in groups)) for pc, groups in pc_grouped]\n",
    "items_by_post=sorted(items_by_post)\n",
    "postal_totals = items_by_post[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code took even more time to run.\n",
    "'''\n",
    "for code in practice_postal:\n",
    "    for dictn in joined:\n",
    "        if dictn['practice'] == code:\n",
    "            dictn['post_code'] = practice_postal[code]\n",
    "        else:\n",
    "            pass\n",
    "joined\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorry code!\n",
    "'''def get_from(qty, datab):\n",
    "    content = []\n",
    "    for dict in datab:\n",
    "        content.append(dict[qty])\n",
    "        \n",
    "    return content\n",
    "    \n",
    "get_from('practice', joined)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''get_from('practice', scripts)[-1]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def nget(qty):\n",
    "    content = []\n",
    "    for dict in practices:\n",
    "        content.append(dict[qty])\n",
    "        \n",
    "    return content\n",
    "\n",
    "def get_from(qty, datab):\n",
    "    content = []\n",
    "    for dict in datab:\n",
    "        content.append(dict[qty])\n",
    "        \n",
    "    return content\n",
    "    \n",
    "\n",
    "\n",
    "def group_by_field_from(data, key_field, field2 ):\n",
    "    unq_key_field = list(set(get_from(key_field, data)))\n",
    "    ngroups = {Name: [] for Name in unq_key_field}\n",
    "    for script in data:\n",
    "        if script[key_field] in ngroups:\n",
    "            ngroups[script[key_field]].append(script[field2])\n",
    "    \n",
    "    return ngroups\n",
    "\n",
    "group_by_field_from(joined, 'post_code', 'items')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll group the prescription dictionaries in `joined` by `'post_code'` and sum up the items prescribed in each group, as we did in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''items_by_postt = group_by_field_from(joined, 'post_code', 'items')\n",
    "items_by_post = dict(sorted(items_by_postt.items()))\n",
    "assert items_by_post == items_by_postt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''postal_total = []\n",
    "for k in items_by_post.keys():\n",
    "    for v in items_by_post.values():\n",
    "        if items_by_post[k] == v:\n",
    "            postal_total.append((k, sum(v)))\n",
    "        else:\n",
    "            pass\n",
    "postal_total'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(postal_total[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = scripts[:]\n",
    "\n",
    "for script in joined:\n",
    "    script['post_code'] = practice_postal[script['practice']]\n",
    "\n",
    "pc_grouped = list(group_by_field(joined, ('post_code',)).items())\n",
    "\n",
    "items_by_post = [(pc[0], sum(group['items'] for group in groups)) for pc, groups in pc_grouped]\n",
    "items_by_post=sorted(items_by_post)\n",
    "postal_totals = items_by_post[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  1.0\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "#postal_totals = postal_total[:100]\n",
    "#postal_totals = [('B11 4BW', 20673)] * 100\n",
    "\n",
    "grader.score.pw__postal_totals(postal_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: items_by_region\n",
    "\n",
    "Now we'll combine the techniques we've developed to answer a more complex question. Find the most commonly dispensed item in each postal code, representing the results as a list of tuples (`post_code`, `bnf_name`, amount dispensed as proportion of total). Sort your results ascending alphabetically by post code and take only results from the first 100 post codes.\n",
    "\n",
    "**NOTE:** We'll continue to use the `joined` variable we created before, where we've chosen the alphabetically first postal code for each practice. Additionally, some postal codes will have multiple `'bnf_name'` with the same number of items prescribed for the maximum. In this case, we'll take the alphabetically first `'bnf_name'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate the total items of each `'bnf_name'` prescribed in each `'post_code'`. Use the techniques we developed in the previous questions to calculate these totals. You should have 141196 `('post_code', 'bnf_name')` groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert len(total_items_by_bnf_post) == 141196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def group_by_fields(data, fields):\n",
    "    ''' Receives a list and a tuple of fields and returns a list of dicts grouped by fields'''\n",
    "    from itertools import groupby\n",
    "    from operator import itemgetter\n",
    "    grouper = itemgetter(*fields)\n",
    "    result = []\n",
    "    for key, grp in groupby(sorted(data, key = grouper), grouper): \n",
    "        # We must be sure key is a tuple\n",
    "        if not isinstance(key, tuple):\n",
    "            key = (key,)\n",
    "        temp_dict = dict(zip([*fields], [*key]))\n",
    "        temp_dict[\"items\"] = sum(item[\"items\"] for item in grp)\n",
    "        result.append(temp_dict)\n",
    "    return result\n",
    "\n",
    "\n",
    "groups = group_by_fields(practices, ('post_code','bnf_name'))\n",
    "\n",
    "total_items_by_bnf_post = groups'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert len(total_items_by_post) == 118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `total_items` to find the maximum item total for each postal code. To do this, we will want to regroup `total_items_by_bnf_post` by `'post_code'` only, not by `('post_code', 'bnf_name')`. First let's turn `total_items` into a list of dictionaries (similar to `scripts` or `practices`) and then group it by `'post_code'`. You should have 118 groups in the resulting `total_items_by_post` after grouping `total_items` by `'post_code'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''total_items = []\n",
    "for pc, v in total_items_by_bnf_post.items():\n",
    "    total_items.append({\"post_code\": pc[0], \"bnf_name\": pc[1], \"items\": v})\n",
    "\n",
    "total_items_by_post = group_by_field(total_items, ('post_code',))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will aggregate the groups in `total_by_item_post` to create `max_item_by_post`. Some `'bnf_name'` have the same item total within a given postal code. Therefore, if more than one `'bnf_name'` has the maximum item total in a given postal code, we'll take the alphabetically first `'bnf_name'`. We can do this by [sorting](https://docs.python.org/2.7/howto/sorting.html) each group according to the item total and `'bnf_name'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_item_by_post = max(group_by_field(total_items, ('post_code',))) # use your logic here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to express the item totals as a proportion of the total amount of items prescribed across all `'bnf_name'` in a postal code, we'll need to use the total items prescribed that we previously calculated as `items_by_post`. Calculate the proportions for the most common `'bnf_names'` for each postal code. Format your answer as a list of tuples: `[(post_code, bnf_name, total)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''items_by_region = []\n",
    "\n",
    "for pc, v in total_items_by_bnf_post.items():\n",
    "    if max_item_by_post[pc[0]] == v: # only append on max items of that bnf_names\n",
    "        items_by_region.append(pc + (v/total_items_by_post[pc[0]],))\n",
    "\n",
    "items_by_region = sorted(items_by_region, key=lambda x: x[0])[:100]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#items_by_region = [('B11 4BW', 'Salbutamol_Inha 100mcg (200 D) CFF', 0.0341508247)] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_field(data, fields):\n",
    "    names = {tuple(item[field] for field in fields) for item in data}\n",
    "    groups = {name: [] for name in names}\n",
    "    for item in data:\n",
    "        name = tuple(item[field] for field in fields)\n",
    "        groups[name].append(item)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_postal = {}\n",
    "for practice in practices:\n",
    "    code = practice['code']\n",
    "    if code not in practice_postal:\n",
    "        practice_postal[code] = practice['post_code']\n",
    "    else:\n",
    "        practice_postal[code] = min(practice_postal[code], practice['post_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_grouped = group_by_field(joined, ('post_code','bnf_name')).items()\n",
    "\n",
    "total_items_by_bnf_post= {name: sum(group['items'] for group in groups) for name, groups in name_grouped}\n",
    "\n",
    "total_items= [{'post_code': tup[0], 'bnf_name': tup[1], 'total' : tot} for tup, tot in list(total_items_by_bnf_post.items())]\n",
    "\n",
    "total_items_by_post = group_by_field(total_items, ('post_code',))\n",
    "\n",
    "max_items_by_post = [sorted(group, key=lambda mem: (-mem['total'], mem['bnf_name']))[0] for group in total_items_by_post.values()]\n",
    "\n",
    "result= [(item['post_code'], item['bnf_name'],item['total'] /dict(items_by_post)[item['post_code']]) for item in max_items_by_post]\n",
    "\n",
    "# Take the first 100 elements and pass it to the grader\n",
    "items_by_region = sorted(result)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Past office hours youtube video link\n",
    "\n",
    "https://www.youtube.com/playlist?list=PLeDYvCW3J3jnT66OZ8bFWrD6fK_Hey92i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  1.0\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "grader.score.pw__items_by_region(items_by_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2017 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
